# Emovision AI

 일반적으로 사람은 대화할 때 대화의 내용, 상황 등 언어적 요소와 표정, 몸짓 등의 비언어적 요소를 판단하여 상대의 의도를 파악합니다. 그러나 시각장애인의 경우 언어적 요소는 충분히 파악이 가능하지만 표정 등의 비언어적 요소에 대한 정보를 파악하기가 어려워 소통에 불편함을 느끼는 일이 많습니다. 저희는 시각장애인들에게 대화에 필요한 시각적 정보를 제공함으로써 보다 편리한 소통을 할 수 있고,  대화중인 시각장애인에게 방해가 되지 않도록 진동을 통해 정보를 전달하는 보조적인 시스템을 만들어 문제를 해결하고자 합니다.

![2023전자공학 창의설계 경진대회-1](https://github.com/ag-jung-0222/Emo-Vision-AI/assets/66015827/1c3f4991-c765-44fb-862d-48adb457246a)
